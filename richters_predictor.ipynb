{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "TRAIN_FRAC = 0.85 # fraction of the labeled data to use for training, remainder is used for validation\n",
    "RANDOM_STATE = 123 # random state for random sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_all = pd.read_csv('train_values.csv')\n",
    "label_data_all = pd.read_csv('train_labels.csv')\n",
    "test_data_all = pd.read_csv('test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect columns\n",
    "train_data_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(train_df):\n",
    "    for col in train_df.columns:\n",
    "        if train_df[col].dtypes == 'object':\n",
    "            dummy_labels = [col + '_' + str(xx) for xx in range(train_df[col].nunique())]\n",
    "            train_df[dummy_labels] = pd.get_dummies(train_df[col])\n",
    "            train_df.drop(col,axis=1,inplace=True)\n",
    "    return train_df\n",
    "\n",
    "train_data_all = one_hot(train_data_all)        \n",
    "for col in train_data_all.columns: print(col, '\\t',train_data_all[col].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "label_data_all[['1','2','3']] = pd.get_dummies(label_data_all['damage_grade'])\n",
    "label_data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "data_train_unscaled = train_data_all.sample(frac=TRAIN_FRAC,random_state=RANDOM_STATE)\n",
    "data_val_unscaled = train_data_all.drop(data_train_unscaled.index,axis=0)\n",
    "label_train = label_data_all.sample(frac=TRAIN_FRAC,random_state=RANDOM_STATE)\n",
    "label_val = label_data_all.drop(label_train.index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "mm_scaler = preprocessing.StandardScaler()\n",
    "scale_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', \n",
    "              'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage']\n",
    "data_train = data_train_unscaled.copy()\n",
    "data_train[scale_cols] = mm_scaler.fit_transform(data_train[scale_cols])\n",
    "data_val = data_val_unscaled.copy()\n",
    "data_val[scale_cols] = mm_scaler.transform(data_val[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class weights\n",
    "class_weights = compute_class_weight('balanced',\n",
    "                                    classes=np.unique(label_train['damage_grade'].values),\n",
    "                                    y=label_train['damage_grade'].values)\n",
    "weights_dict = {np.unique(label_train['damage_grade'].values)[kk]:class_weights[kk] for kk in range(len(class_weights))}\n",
    "weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "cl_f = RandomForestClassifier(random_state = 1)\n",
    "n_estimators = [50, 100, 300, 500, 800]\n",
    "max_depth = [5, 8, 15, 25, 35]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "hyper_f = dict(n_estimators = n_estimators, \n",
    "               max_depth = max_depth,\n",
    "               min_samples_split = min_samples_split,\n",
    "               min_samples_leaf = min_samples_leaf)\n",
    "grid_f = GridSearchCV(cl_f, hyper_f, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "best_f = grid_f.fit(data_train.values.astype(float), label_train.values[:,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "pred_val = clf.predict(data_val)\n",
    "plot_confusion_matrix(clf,data_val,label_val.values[:,1].astype(int))\n",
    "print(f1_score(label_val.values[:,1].shape, pred_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
